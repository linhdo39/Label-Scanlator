{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_scrapper_and_sentiment_analyser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHC57d21qNZr",
        "outputId": "9c9c2d4d-e7ec-46aa-f005-762f75391535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install gensim\n",
        "!pip install newspaper3k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 2.7MB/s \n",
            "\u001b[?25hCollecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/9e/578ea24d0149a5c179ded8ea53e2b8fc35d22f7bfdee9564844873b147ea/tldextract-3.0.2-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Building wheels for collected packages: feedfinder2, jieba3k, tinysegmenter, sgmllib3k\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3355 sha256=34d1b770aee5d32e32564270141cc82ca8e3f8ad7f68f294332e5666ae6e9f06\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=33ff33078cafbdc84cbc6aa549c6a982ca34328756c1652983f4a1ae8e5c8c49\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13538 sha256=20cb74500d7ad495d8128bb5f35297d3885286c20656c01239ac72a149fe3fa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp36-none-any.whl size=6067 sha256=9931a602c45f86e2bff68119d39bc9cafe7b5ea131b3e6b922095074150b82e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built feedfinder2 jieba3k tinysegmenter sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, cssselect, feedfinder2, jieba3k, tinysegmenter, requests-file, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-g3zzcKwz80"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from gensim.summarization.summarizer import summarize\n",
        "from gensim.summarization import keywords\n",
        "from newspaper import Article\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import urllib.parse\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYmHNu6Hc5wu"
      },
      "source": [
        "def googleSearch(ingr):\n",
        "    g_clean = []\n",
        "    url = 'https://www.google.com/search?client=ubuntu&channel=fs&q={}&ie=utf-8&oe=utf-8'.format(ingr)\n",
        "    try:\n",
        "            html = requests.get(url)\n",
        "            if html.status_code==200:\n",
        "                soup = BeautifulSoup(html.text, 'lxml')\n",
        "                a = soup.find_all('a')\n",
        "                for i in a:\n",
        "                    k = i.get('href')\n",
        "                    try:\n",
        "                        m = re.search(\"(?P<url>https?://[^\\s]+)\", k)\n",
        "                        n = m.group(0)\n",
        "                        rul = n.split('&')[0]\n",
        "                        domain = urlparse(rul)\n",
        "                        if(re.search('google.com', domain.netloc)):\n",
        "                            continue\n",
        "                        else:\n",
        "                            g_clean.append(rul)\n",
        "                    except:\n",
        "                        continue\n",
        "    except Exception as ex:\n",
        "            print(str(ex))\n",
        "    finally:\n",
        "            return g_clean\n",
        "\n",
        "def analyse_sentiments(s_line):\n",
        "    analyser = SentimentIntensityAnalyzer()\n",
        "\n",
        "    vs = analyser.polarity_scores(s_line)\n",
        "\n",
        "    if vs['compound'] >= 0.1:\n",
        "        return vs['compound']\n",
        "    elif vs['compound'] <= -0.1:\n",
        "        return vs['compound']\n",
        "    else:\n",
        "        return vs['compound']\n",
        "\n",
        "def safe_or_not(s):\n",
        "    if s >= 2.8:\n",
        "        return 'healthy'\n",
        "    elif s <= 1.8:\n",
        "        return 'potentially harmful'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "def avg(lst, n):\n",
        "    return sum(lst)/n\n",
        "\n",
        "def scrapper(url):\n",
        "    article = Article(url)\n",
        "\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    return article.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRvb5t45bsel"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5oH99UheRtm"
      },
      "source": [
        "lst_of_ingredients = ['parabens', 'sulfates', 'phthalates', 'fragarance', 'formaldehyde', 'phenoxyethanol', 'methanol', 'polyethylene glycols']\n",
        "health1 = []\n",
        "\n",
        "for i in lst_of_ingredients:\n",
        "    search = 'disadvantages of {} for skin'.format(i)\n",
        "    l = googleSearch(search)\n",
        "    l = l[:6]\n",
        "\n",
        "    score = []\n",
        "    for url in l:\n",
        "        try:\n",
        "            score.append(analyse_sentiments(scrapper(url)))\n",
        "        except:\n",
        "            pass\n",
        "    s = avg(score, len(lst_of_ingredients)/3)\n",
        "    health1.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPfdFY6cmfZX"
      },
      "source": [
        "health2 = []\n",
        "\n",
        "for i in lst_of_ingredients:\n",
        "    search = 'advantages of {} for skin'.format(i)\n",
        "    l = googleSearch(search)\n",
        "    l = l[:6]\n",
        "\n",
        "    score = []\n",
        "    for url in l:\n",
        "        try:\n",
        "            score.append(analyse_sentiments(summarize(scrapper(url), ratio=0.7)))\n",
        "        except:\n",
        "            pass\n",
        "    s = avg(score, len(lst_of_ingredients)/3)\n",
        "    health2.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNwVtPiTb9cx",
        "outputId": "b378ddf5-5628-45e3-e4e7-e6c7fcc3e206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "end = time.time()\n",
        "\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.83723640441895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S95DKYWjgQg"
      },
      "source": [
        "for i in range(len(lst_of_ingredients)):\n",
        "    a = health1[i] + health2[i]\n",
        "    print(lst_of_ingredients[i], safe_or_not(a), 'Confidence :', a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUfYaNfRWlLS"
      },
      "source": [
        "for i in range(len(lst_of_ingredients)):\n",
        "    print(lst_of_ingredients[i], '-', health1[i], health2[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUZtq9XRZQtl"
      },
      "source": [
        "# Quick Summary\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "   \n",
        "for c in lst_of_ingredients:\n",
        "    search = \"is {} safe for hair\".format(c)\n",
        "\n",
        "    url = f\"https://www.google.com/search?&q={search}\"\n",
        "   \n",
        "    req = requests.get(url)\n",
        "    print(req)\n",
        "\n",
        "    sor = BeautifulSoup(req.text, \"html.parser\")\n",
        "    s = sor.find(\"div\", class_='BNeawe').text\n",
        "\n",
        "    print(c, '-',s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdOynyCucvii"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}